# nfl-rules-rag-assistant ğŸˆ

**nfl-rules-rag-assistant** is a small GenAI project that uses a  
**Retrieval-Augmented Generation (RAG)** pipeline to explain NFL rules  
(and eventually analytics concepts) in plain English.

---

## ğŸ” What it does

- Ingests text from the **NFL rulebook** and your own **analytics notes**
- Stores that knowledge in a local **vector database**
- Uses **OpenAI embeddings + an LLM** to:
  - Retrieve the most relevant rule / analytics snippets
  - Generate grounded explanations to questions like:
    - â€œWhat is roughing the passer?â€
    - â€œWhatâ€™s the difference between illegal contact and defensive holding?â€
    - â€œWhat actually counts as a catch in the NFL?â€

All answers are **grounded in your local text**, not just the modelâ€™s general memory.


---

## âœ¨ Features

- ğŸ“š **RAG over NFL rules & notes**  
  - Load your own `rulebook.txt` and analytics text files
  - Chunk + embed them into a local ChromaDB index

- ğŸ§  **LLM-powered rule explanations**  
  - Ask natural language questions like:
    - `What is defensive pass interference?`
    - `How is offensive pass interference enforced?`
  - The assistant uses only retrieved context to build answers

- ğŸ›¡ï¸ **Grounded, low-hallucination design**  
  - Prompt explicitly tells the model to use **only** provided context
  - If something isnâ€™t in your data, itâ€™s allowed to say â€œI donâ€™t knowâ€

## ğŸ§± Tech stack

- **Language:** Python
- **LLM:** OpenAI (chat + embedding APIs)
- **Vector store:** ChromaDB (persistent local index)
- **Config:** dotenv (`.env` for secrets)
- **Interface:** Command-line (CLI) for now

## ğŸ§  How it works (architecture)

1. **Ingestion & chunking**
   - Load `.txt` files under `data/rulebook/` and `data/analytics/`.
   - Split them into smaller, paragraph-sized chunks for better retrieval.

2. **Embedding & indexing**
   - Use OpenAIâ€™s `text-embedding-3-small` model to embed each chunk.
   - Store embeddings + raw text in a local ChromaDB collection at `index/chroma/`.

3. **Retrieval**
   - When you ask a question, embed the query and retrieve the top-k most similar chunks from the index.

4. **Grounded generation (RAG)**
   - Build a prompt that includes:
     - The retrieved context
     - The userâ€™s question
     - Instructions to **only** use the provided context and say â€œI donâ€™t knowâ€ if needed.
   - Call an OpenAI chat model (e.g. `gpt-5.1-mini`) to generate the final explanation.

## âš ï¸ Limitations

- The assistant only knows what you put under `data/`. If a rule or concept
  isnâ€™t included there, it may honestly say it doesnâ€™t know.
- The summaries are **not** official NFL legal wording; they are informal,
  plain-English explanations based on your text.
- Retrieval quality depends on how well the rulebook/notes are written and chunked.
- This project is intended for learning and personal use, not for making
  officiating decisions or betting decisions.


---

## ğŸ—‚ Project structure

```text
nfl-rules-rag-assistant/
  â”œâ”€ data/
  â”‚   â”œâ”€ rulebook/
  â”‚   â”‚   â””â”€ rulebook.txt          # your NFL rule summaries
  â”‚   â””â”€ analytics/
  â”‚       â””â”€ analytics_notes.txt   # optional: analytics articles/notes
  â”œâ”€ index/
  â”‚   â””â”€ chroma/                   # vector DB will be created here
  â”œâ”€ src/
  â”‚   â”œâ”€ build_index.py            # ingests docs & builds vector index
  â”‚   â””â”€ nfl_assistant.py          # CLI for asking rule questions (RAG)
  â”œâ”€ .env.example
  â”œâ”€ requirements.txt
  â”œâ”€ .gitignore
  â””â”€ README.md
